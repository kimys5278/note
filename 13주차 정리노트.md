# 13주차 정리노트

상태: 시작 전

## 201904197김유성

### 합성곱 층과 풀링 층이 자세하게 무엇인가?

합성곱 층(Convolutional Layer)은 이미지 처리에서 사용되는 층으로, 입력 데이터에 대해 필터와의 합성곱 연산을 수행하여 특징 맵을 생성한다. 이를 통해 이미지의 특징을 추출하고 공간적인 구조를 파악할 수 있다.

풀링 층(Pooling Layer)은 합성곱 층의 출력인 특징 맵을 다운샘플링하여 크기를 줄이는 역할을 한다. 대표적으로 최대 풀링(Max Pooling)과 평균 풀링(Average Pooling)이 있으며, 이를 통해 특징 맵의 크기를 감소시키고 계산량을 줄일 수 있다.

합성곱 층(Convolutional Layer)은 예를 들어 이미지 인식을 위한 신경망을 구성한다고 가정. 입력 이미지에 대해 합성곱 층은 작은 필터를 적용하여 이미지의 특징을 추출한다. 예를 들어, 강아지를 인식하는 신경망에서 합성곱 층은 강아지의 귀, 코, 눈 등과 같은 특징들을 감지할 수 있다. 이러한 특징들은 여러 개의 필터가 동시에 작동하여 특징 맵을 생성하게 된다.

풀링 층(Pooling Layer)은 예를 들어 합성곱 층에서 생성된 특징 맵의 크기를 줄이는 역할을 한다. 최대 풀링(Max Pooling)은 특징 맵에서 가장 큰 값만 선택하여 다운샘플링한다. 이를 통해 이미지의 위치 변화에 상대적으로 덜 민감해지며, 중요한 특징을 보존하면서 크기를 줄일 수 있다. 예를 들어, 강아지의 얼굴을 인식하는 신경망에서, 최대 풀링은 강아지의 눈, 코, 입 등 중 가장 강조되는 특징을 선택하고, 불필요한 세부 정보를 감소시킨다.

이와 같이, 합성곱 층과 풀링 층은 이미지 처리에서 중요한 역할을 한다. 합성곱 층은 이미지의 특징을 추출하고, 풀링 층은 특징 맵의 크기를 줄여 계산량을 줄이고 중요한 정보를 보존한다.

### 평균 풀링 층,전역 평균 풀링 층,최대/평균을 계산하는 풀링층에 대한 자세한 내용을 알고싶다.

### <평균 풀링 층>

평균 풀링 층(Average Pooling Layer)은 특징 맵에서 영역의 평균 값을 계산하여 다운샘플링하는 역할을 한다. 이를 통해 특징 맵의 크기를 줄이고 계산량을 감소시킬 수 있다. 평균 풀링은 영역의 평균 값을 사용하기 때문에 최대 풀링에 비해 더 많은 정보를 보존한다. 평균 풀링은 주로 이미지 분류 작업에서 사용되며, 이미지의 전반적인 특징을 보존하면서 이미지의 세부 사항을 상대적으로 줄이는 데 적합하다.

### <평균 풀링 층>

평균 풀링 층(Average Pooling Layer)은 특징 맵에서 영역의 평균 값을 계산하여 다운샘플링하는 역할을 한다. 이를 통해 특징 맵의 크기를 줄이고 계산량을 감소시킬 수 있다. 평균 풀링은 영역의 평균 값을 사용하여 특징 맵을 다운샘플링한다. 이 방법은 최대 풀링에 비해 더 많은 정보를 보존하며, 이미지 분류 작업에서 주로 사용된다. 평균 풀링은 이미지의 전반적인 특징을 보존하면서 이미지의 세부 사항을 상대적으로 줄이는 데 적합하다.

### <전역 평균 풀링 층>

전역 평균 풀링 층(Global Average Pooling Layer)은 특징 맵의 전체 영역에 대한 평균 값을 계산하여 다운샘플링한다. 이 방법은 특징 맵의 크기를 크게 줄이며, 적은 수의 파라미터로 전체 영역에 대한 정보를 요약한다. 전역 평균 풀링은 주로 마지막 합성곱 층 뒤에 사용되며, 분류 작업에서 클래스별 확률을 계산하기 위해 사용된다. 전역 평균 풀링은 네트워크의 전체적인 구조를 간단하게 만들어 파라미터의 수를 줄이는 장점이 있다.

### VGGNet에 특징이 무엇인가?

VGGNet은 2014년에 개발된 이미지 인식을 위한 합성곱 신경망 구조이다. 이 네트워크는 깊은 구조로 알려져 있으며, 작은 크기의 커널을 사용하여 깊은 합성곱 층과 풀링 층으로 구성되어 있다.

VGGNet의 핵심 아이디어는 작은 필터를 연속적으로 쌓아 깊은 신경망을 구성하는 것이다. 특히, VGGNet은 3x3 크기의 작은 필터를 사용하여 2개의 3x3 합성곱 층을 연속적으로 쌓은 구조를 가지고 있다. 이렇게 작은 필터를 사용하면 신경망이 더 깊어지면서 특징을 더 정교하게 추출할 수 있다.

VGGNet은 합성곱 층과 풀링 층의 연속적인 구조를 반복하여 신경망을 깊게 만든다. 이러한 구조는 일반적으로 16개 또는 19개의 합성곱 층으로 구성된다. 이러한 깊은 구조는 다양한 이미지 인식 작업에서 우수한 성능을 보여준다.

VGGNet의 장점 중 하나는 간단하면서도 효과적인 구조를 가지고 있다는 점이다. 작은 필터를 사용하고 합성곱 층과 풀링 층의 연속적인 구조를 반복함으로써 네트워크를 간결하고 효율적으로 만들 수 있습니다. 이러한 구조는 많은 컴퓨터 비전 태스크에 적용될 수 있다.

하지만 VGGNet은 깊은 구조를 가지면서 많은 계산 비용이 필요하다는 단점도 있다. 특히 학습 및 추론 단계에서 많은 계산 리소스가 필요할 수 있다.

### ResNet (Residual Network)의 특징이 무엇인가?

ResNet은 2015년에 소개된 심층 신경망 구조로, 컴퓨터 비전 분야에서 매우 성공적으로 적용되었다. ResNet의 주요 아이디어는 스킵 연결(skip connection)이라는 개념을 도입한 것이다.

스킵 연결은 네트워크의 일부를 건너뛰어 입력과 출력을 직접 연결하는 것을 의미한다. 이렇게 스킵 연결을 사용하면 네트워크가 더 깊어지더라도 그레디언트 소실(gradient vanishing) 문제를 완화할 수 있다. 그레디언트 소실 문제는 깊은 신경망에서 그레디언트가 너무 작아져 역전파 과정에서 제대로 전달되지 않는 문제다.

ResNet은 기본적으로 잔차 블록(residual block)이라는 구조로 이루어져 있습니다. 잔차 블록은 입력과 출력을 직접 연결한 스킵 연결과 함께 합성곱 층을 포함하고 있다.

ResNet은 많은 변종이 존재하며, 대표적인 예로는 ResNet-50, ResNet-101, ResNet-152 등이 있다. 이러한 변종들은 서로 다른 깊이와 파라미터 수를 가지고 있으며, 특정한 컴퓨터 비전 태스크에 맞게 선택할 수 있다.

ResNet은 이미지 인식, 객체 검출, 세분화 등 다양한 컴퓨터 비전 태스크에서 우수한 성능을 보여주었다. 더불어, ResNet은 다른 신경망 구조에 비해 상대적으로 적은 계산 비용을 요구하고, 높은 정확도를 제공하는 장점을 가지고 있다.

따라서, ResNet은 깊은 신경망에서 그레디언트 소실 문제를 해결하고, 높은 성능과 효율성을 동시에 제공하는 신경망 구조로 널리 사용되고 있다.

## 201904223 이동현

### **합성곱 층과 풀링 층은 CNN 구조에서 어떤 역할을 하는가?**

합성곱 층은 이미지의 공간 정보를 보존하면서 이미지에서 특징을 추출하는 역할을하는데 이는 필터라고 불리는 작은 매트릭스를 사용해 입력 데이터에 합성곱 연산을 적용함으로써 이루어진다.

필터는 이미지의 작은 영역에 대해 슬라이딩 윈도우 방식으로 적용되며, 각 서브 영역과 필터의 요소 간에 곱셈과 덧셈 연산이 이루어지고 이런 과정을 통해 얻어진 결과를 특징 맵이라고 한다.

필터의 값은 학습 과정에서 업데이트되며, 이 필터들이 이미지의 다양한 특징을 잡아내게 되는데 따라서, 합성곱 층은 이미지의 로컬 특징을 추출하는 데 중요한 역할을 합니다.

풀링 층은 합성곱 층을 통해 얻은 특징 맵의 크기를 줄이는 역할을 하며 이는 학습해야 할 파라미터의 수를 줄이고, 모델의 복잡도를 낮추는 효과를 가져온다. 이로 인해 과적합을 방지하고, 계산 효율성을 높일 수 있다.

풀링은 주로 최대 풀링과 평균 풀링 두 가지 방법이 사용되며, 이는 각각 서브 영역의 최대값 또는 평균값을 추출하는 방식으로 동작하는데 풀링 층은 특징 맵의 공간적 크기를 줄이면서도 중요한 정보를 보존할 수 있도록 도와준다. 또한, 풀링 층을 통해 모델은 입력의 작은 변화에 덜 민감해지며, 이는 일종의 공간적 인변성을 제공합니다.

### **케라스를 이용해 사전 훈련된 모델을 사용하는 방법과 그 장점은?**

케라스는 파이썬으로 작성된 오픈 소스 신경망 라이브러리로, 빠르게 실험을 할 수 있게 설계되었는데 이는 사용자 친화적인 API로 구성되어 있어 딥러닝 모델을 쉽고 빠르게 개발할 수 있다.

케라스에서는 사전 훈련된 모델을 쉽게 사용할 수 있는데 종류에는 VGG16, VGG19, ResNet, InceptionV3 등과 같은 모델들이 포함되어 있다. 사전 훈련된 모델을 사용하는 방법은 크게 두 가지로 되어있는데 첫 번째는 특징 추출 방식으로, 사전 훈련된 모델을 특징 추출기로 사용하는 방법이다. 이 경우, 사전 훈련된 모델 위에 새로운 분류기를 추가하고, 이 분류기만 학습을 진행한다. 두 번째 방법은 미세 조정 방식으로, 사전 훈련된 모델의 일부 레이어의 가중치를 업데이트하는 방법인데 이 경우, 모델의 상위 레이어들을 재학습시켜 특정 문제에 좀 더 잘 맞게 조정한다.

사전 훈련된 모델을 사용하는 장점에는 무엇이 있냐하면 먼저 사전 훈련된 모델은 대규모 데이터셋에서 학습되었기에 소량의 데이터만 가지고 있어도 이를 활용해 비교적 정확한 예측을 할 수 있다. 즉, 데이터가 부족한 상황에서도 뛰어난 성능을 낼 수 있게 되는것 그 다음으로 이미 학습된 가중치를 사용하므로, 모델을 처음부터 학습시킬 필요가 없기에 계산 시간이 단축된다. 마지막으로 사전 훈련된 모델은 이미 다양한 특징을 학습했기 때문에, 이를 기반으로 다양한 문제에 적용할 경우 충분히 높은 성능을 얻을 수 있다.

### **객체 탐지와 시맨틱 분할의 차이점은?**

객체 탐지와 시맨틱 분할은 모두 이미지에서 특정 객체를 인식하는 작업이지만 이 두 기술은 객체를 인식하고 표현하는 방식에서 차이가 있다.

객체 탐지는 일반적으로 이미지에 있는 개별 객체를 인식하고, 그 위치를 사각형 바운딩 박스로 표현하는 작업으로 이미지에서 어떤 객체가 어디에 있는지를 알려주는데 이를 위해, 객체 탐지 알고리즘은 클래스 레이블과 바운딩 박스의 좌표를 예측한다. 대표적인 객체 탐지 알고리즘으로는 YOLO, SSD, Faster R-CNN 등이 있다.

반면에, 시맨틱 분할은 이미지를 픽셀 단위로 분류하여, 같은 클래스 레이블을 가진 픽셀들끼리 연결하여 하나의 영역으로 표시하는 작업으로 객체의 정확한 형상에 대한 정보를 제공한다. 즉, 시맨틱 분할은 이미지에서 어떤 픽셀이 어떤 객체에 속하는지를 알려주는 것이고 이를 위해 시맨틱 분할 알고리즘은 각 픽셀의 클래스 레이블을 예측한다. 대표적인 시맨틱 분할 알고리즘으로는 FCN, U-Net, SegNet 등이 있다.

이 두 기술의 주요 차이점은, 객체 탐지가 객체의 위치와 크기를 대략적으로 표현하는 반면, 시맨틱 분할은 객체의 정확한 위치와 형상을 픽셀 단위로 표현한다는 것이다. 시맨틱 분할은 객체 탐지보다 더욱 세밀한 정보를 제공하지만 시맨틱 분할은 픽셀 단위의 예측이 필요하기 때문에 계산 복잡성이 더 높을 수 있다.
