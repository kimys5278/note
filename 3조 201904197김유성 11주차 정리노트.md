# 11주차 정리노트

상태: 시작 전

### 201904197 김유성

## 결정경계가 왜 중요하나?

결정 경계는 군집화나 분류 작업에서 중요한 개념임. 결정 경계는 데이터를 서로 다른 그룹 또는 클래스로 나누는 경계를 의미. 결정 경계를 잘 구분하는 모델은 데이터를 정확하게 분류하거나 그룹화할 수 있음.

결정 경계의 중요성은 다음과 같은 이유로 설명됩니다:

- **분류 작업:** 결정 경계를 통해 데이터를 서로 다른 클래스로 분류할 수 있음. 예를 들어, 스팸 메일과 일반 메일을 분류하는 작업에서 결정 경계는 스팸과 일반 메일을 구분하는 기준이 됨. 결정 경계를 명확하게 구분하는 모델은 정확한 분류를 수행할 수 있음.
- **군집화 작업:** 결정 경계는 군집화 작업에서 서로 다른 군집을 나누는 기준이 됨. 군집화는 비슷한 특성을 가진 데이터를 그룹화하는 작업임. 결정 경계를 잘 구분하는 모델은 데이터를 정확하게 군집화할 수 있음.

결정 경계의 중요성은 모델의 성능과 해석력에도 영향을 줌. 결정 경계를 명확하게 구분하는 모델은 데이터를 더 정확하게 분류하거나 군집화할 수 있으며, 이를 통해 모델의 성능을 개선할 수 있음. 또한 결정 경계를 이해하는 것은 모델의 동작을 해석하고 설명하는 데에도 도움.

## 가우시안 혼합 – GMM 활용에서 GMM이 무엇인가?

**가우시안 혼합 – GMM 활용에서 GMM이 무엇인가?**

가우시안 혼합 모델(Gaussian Mixture Model)은 데이터를 여러 개의 가우시안 분포로 표현하는 확률 모델.가우시안 혼합 모델은 주어진 데이터가 여러 개의 클러스터로 구성되어 있을 때, 각 클러스터의 가우시안 분포와 해당 클러스터에 속할 확률을 추정.이렇게 추정된 가우시안 분포들을 결합하여 전체 데이터의 확률분포를 모델링함.

가우시안 혼합 모델은 다양한 응용 분야에서 사용됩니다. 예를 들어 금융 거래 데이터에서 이상치를 탐지하거나, 언어 모델에서 단어 분포를 모델링하는 데 사용될 수 있음.가우시안 혼합 모델은 데이터의 분포를 유연하게 모델링할 수 있으며, 이를 통해 데이터에 대한 통계적 모델링과 분석이 가능해짐.

가우시안 혼합 모델은 기대값-최대화(Expectation-Maximization, EM) 알고리즘을 통해 모델 파라미터를 추정.. EM 알고리즘은 초기에 임의의 파라미터를 설정한 후, 데이터의 최우추정을 통해 파라미터를 반복적으로 업데이트합니다. 이 과정을 반복하여 모델의 파라미터를 수렴.

가우시안 혼합 모델은 클러스터링, 이상치 탐지, 차원 축소 등 다양한 문제에 활용될 수 있는 강력한 확률 모델.

---

## 가우시안 혼합모델을 어떤 연구에서 사용할까?

1. **이상치 탐지 (Anomaly Detection):** GMM은 데이터의 정상적인 분포를 모델링하고, 이 분포에서 벗어나는 데이터 포인트를 이상치로 감지하는 데 사용됩니다. 금융 거래에서 사기 탐지, 네트워크 보안에서 이상 행동 탐지 등 다양한 분야에서 활용됩니다.
2. **자연어 처리 (Natural Language Processing, NLP):** 텍스트 데이터에서 단어 또는 문서의 잠재 의미를 추출하거나, 토픽 모델링과 같은 NLP 작업에서 GMM이 사용됩니다. 문서 군집화, 주제 모델링, 감성 분석, 텍스트 분류 등에서 활용 가능합니다.
3. **영상 처리 (Computer Vision):** GMM은 이미지에서 픽셀, 텍스처, 물체 또는 물체의 움직임을 모델링하고 분할하는 데 사용됩니다. 객체 추적, 이미지 분할, 이미지 복원 등에서 응용됩니다.
4. **음성 처리 (Speech Processing):** 음성 신호를 다룰 때 GMM은 음성 특징 추출, 음성 인식, 화자 인식과 같은 작업에서 활용됩니다.
5. **패턴 인식 (Pattern Recognition):** 패턴 인식 분야에서 GMM은 다양한 응용에 사용됩니다. 지문 인식, 얼굴 인식, 필기체 인식, 동작 인식 등에서 활용 가능합니다.
6. **생물 정보학 (Bioinformatics):** GMM은 유전자 발현 데이터를 군집화하거나, 단백질 구조를 분석하고 예측하는 데 사용됩니다. 유전체 분석, 단백질 접힘 예측, 분자 구조 분석 등에서 응용됩니다.
7. **의료 이미지 분석 (Medical Image Analysis):** 의료 영상 데이터에서 조직, 종양, 혈관 등을 분할하거나 병변을 탐지하는 데 GMM이 사용됩니다. 의료 영상 분석, 의료 진단, 암 탐지 등에서 활용됩니다.
8. **금융 분석 (Financial Analysis):** 금융 시장 데이터를 분석하여 주식 가격 예측, 자산 포트폴리오 최적화, 리스크 관리 등에 GMM을 활용합니다.

이외에도 GMM은 데이터 분석과 모델링에서 확률적인 관점에서 다양한 문제를 다루는 데 사용됩니다. GMM은 데이터의 분포를 더 정확하게 모델링하고, 이를 통해 다양한 응용 분야에서 유용한 정보를 추출하고 예측하는 데 도움을 줄 수 있습니다.

---

1. **K-평균 (K-Means):**
- **설명:** K-평균은 데이터를 K개의 클러스터로 나누는 알고리즘으로, 각 클러스터의 중심을 찾아가는 방식으로 작동합니다.
- **예시:** 소비자 세분화 연구에서 고객들을 구매 패턴에 따라 클러스터로 그룹화하여 특정 마케팅 전략을 개발하거나, 이미지 데이터에서 비슷한 색상을 가진 픽셀을 클러스터로 묶어 이미지 분할을 수행할 때 사용됩니다.
1. **군집을 사용한 이미지 분할:**
    - **설명:** 이미지 분할은 이미지를 작은 부분으로 나누는 작업으로, 군집화는 픽셀 또는 이미지 영역을 비슷한 특성을 가진 그룹으로 나누어 이미지 분할을 수행합니다.
    - **예시:** 의료 이미지에서 종양을 탐지하기 위해 이미지를 세포와 정상 조직으로 분할하거나, 자율 주행 자동차에서 환경을 이해하기 위해 도로, 차량, 보행자를 분할할 때 사용됩니다.
2. **군집을 사용한 전처리:**
    - **설명:** 데이터 전처리 과정에서 군집화는 유사한 데이터 포인트를 그룹화하여 데이터 정제나 특성 추출에 활용됩니다.
    - **예시:** 텍스트 데이터에서 단어 클러스터링을 수행하여 문서의 토픽을 파악하거나, 음성 데이터에서 발음 패턴을 클러스터링하여 음성 인식 정확도를 향상시킬 때 사용됩니다.
3. **군집을 사용한 준지도 학습:**
    - **설명:** 군집화는 레이블이 지정되지 않은 데이터를 그룹화하여 추가 지도 학습 작업에 활용됩니다.
    - **예시:** 웹 문서를 주제별로 그룹화하고, 일부 문서에만 레이블을 부여하여 검색 엔진을 향상시키거나, 비정상적인 네트워크 트래픽을 식별하기 위해 네트워크 패킷을 클러스터링할 때 사용됩니다.
4. **DBSCAN (Density-Based Spatial Clustering of Applications with Noise):**
    - **설명:** DBSCAN은 밀도 기반 군집 알고리즘으로, 데이터 포인트가 밀도가 높은 지역에 클러스터를 형성하고, 노이즈 데이터를 탐지합니다.
    - **예시:** 공간 데이터에서 지리적으로 밀집된 지역을 식별하거나, 이상치 탐지와 같은 분야에서 이상 행동을 검출할 때 사용됩니다.
5. **가우시안 혼합 (Gaussian Mixture Model):**
    - **설명:** 가우시안 혼합 모델은 데이터를 여러 개의 가우시안 분포로 표현하는 확률 모델입니다.
    - **예시:** 혼합 모델을 사용하여 금융 거래 데이터에서 이상치를 탐지하거나, 언어 모델에서 단어 분포를 모델링하는 데 사용됩니다.
6. **가우시안 혼합을 사용한 이상치 탐지:**
    - **설명:** 가우시안 혼합 모델을 이용하여 데이터의 정상적인 분포를 모델링하고, 그 분포에서 벗어나는 데이터를 이상치로 간주합니다.
    - **예시:** 금융 거래에서 사기 탐지, 제조업에서 장비 고장 탐지 등 이상치 탐지 문제에 사용됩니다.
7. **클러스터 개수 선택하기:**
    - **설명:** 적절한 클러스터 개수를 선택하는 것은 군집화의 성능에 중요한 영향을 미칩니다. 다양한 클러스터 개수에 대한 모델을 평가하고 최적의 개수를 선택하는 작업입니다.
    - **예시:** 엘보우 메서드 또는 실루엣 스코어와 같은 평가 지표를 사용하여 데이터에 가장 적합한 클러스터 개수를 결정할 때 사용됩니다.
8. **베이즈 가우시안 혼합 모델:**
    - **설명:** 베이즈 가우시안 혼합 모델은 가우시안 혼합 모델을 확률적인 방법과 베이즈 통계적 추론을 결합하여 더 정확한 모델링을 제공합니다.
    - **예시:** 의료 진단, 텍스트 분류, 효율적인 데이터 압축과 같은 다양한 응용 분야에서 확률적 모델링에 활용됩니다.
  
9. ### 201904223 이동현

# 군집

- 군집은 추천 시스템이나 이상치 탐지 등에 주로 유용하게 사용되는 도구이다
- 비슷한 샘플을 클러스터로 모으면서 각 샘플은 하나의 그룹에 할당된다
- 하드군집과 소프트 군집이 존재
    - 하드군집은 각샘플에 대해 가장 가까운 클러스터를 선택
    - 소프트 군집은 클러스터마다 샘플의 점수를 부여하고 샘플별로 각 군집 센트로이드와의 거리를 측정한다

## 군집 (이미지 분할)

- 이미지 분할
    - 다양한 클러스터 개수로 k 평균을 사용해 이미지를 세그먼트 여러 개로 분할하는 작업
- 시맨틱 분할
    - 동일한 종류의 물체에 속한 모든 픽셀은 같은 세그먼트에 할당
- 색상 분할
    - K 평균을 이용하여 색상분할 실행

## 군집 (전처리)

- 미니 MNIST 데이터셋 전처리를 예로 보면 전처리 없이 로지스틱회귀 학습시키면 96.89% 정확도이지만 K평균을 전처리 단계로 사용한 후 로지스틱회귀 학습하면 군집에서 데이터셋의 차원은 64 -->50 으로 감소하면서 정확도가 97.78%로 증가

## 군집 (준지도 학습)

- 군집을 사용한 준지도 학습은 레이블이 없는 샘플이 많고 레이블이 있는 샘플이 적을 때 사용한다
- 레이블을 동일한 클러스터에 있는 모든 샘플로 전파하는 레이블 전파 방법도 있다
    - 전파된 레이블이 실제로 매우 좋으면 결과가 좋음

---

# k-평균

- 위의 군집을 이용한 알고리즘 중엔 k-평균 알고리즘이 있다
- 반복 몇 번으로 레이블이 없는 데이터셋을 빠르고 효율적으로 클러스터로 묶는 알고리즘
    - 처음에는 센트로이드를 랜덤하게 선정한다
    - 그리고 수렴할 때까지 다음 과정을 반복한다
        1. 각 샘플을 가장 가까운 센트로이드에 할당
        2. 군집별로 샘플의 평균을 계산하여 새로운 센트로이드 지정
- 이렇게 결정경계 부분의 일부 샘플을 제외하고 기본적으로 군집이 잘 구성된다

### elkan 알고리즘

- 불필요한 거리 계산을 많이 피해 학습 속도 향상시켜주는 알고리즘

### 단점

- 샘플과 센트로이드까지의 거리만 고려되기 때문에 군집의 크기가 서로 많이 다르면 잘 작동하지 않는다

### 한계

- 최적이 아닌 솔루션을 피하려면 알고리즘을 여러 번 실행해야 함
- 클러스터 개수를 미리 지정해야 함
- 클러스터의 크기나 밀집도가 다르거나, 원형이 아닐 경우 잘 작동하지 않음

## k-평균 (센트로이드 초기화)

과정을 반복하기 위해 센트로이드를 초기화할때 방법으로는 다음과 같은 방법들이 있다

1. 관성
- k-mean 모델 평가 방법으로 샘플과 가장 가까운 센트로이드와의 거리의 제곱의 합을 말하며 각 군집이 센트로이드에 얼마나 가까이 모여있는가를 나타냄
1. 좋은 모델 선택법
- 다양한 초기화 과정을 실험한 후에 가장 좋은 것을 선택하는 방법
- 10번 학습 후 가장 낮은 관성을 갖는 모델을 선택
1. k-평균 ++
- 센트로이드를 무작위로 초기화하는 대신 특정 확률분포를 이용하여 선택하는 방법

## k-평균 (미니배치 k-평균)

- 각 반복마다 미니배치를 사용해 센트로이드를 조금씩 이동시키는 방법
- K - 평균 알고리즘 보다 훨씬 빠르면서 이너셔는 일반적으로 조금 더 나쁘고 또한 군집수가 증가할 때 이너셔는 더 나쁘다

## k-평균 (최적의 클러스터 개수 찾기)

k-평균 알고리즘을 사용할땐 클러스터의 개수를 설정하는 것이 중요하고 따라서 다양한 방법으로 최적의 개수를 찾을 수 있음

<aside>
❓ **최적의 클러스터 개수를 찾는 두가지 방법 중에 어떤 방법을 사용하는것이 더 좋을까?**

관성과 실루엣 점수 두가지 방법의 차이점은 다음과 같다

- 관성은 클러스터 내의 데이터 포인트들이 얼마나 잘 모여 있는지를 측정하는 지표이나 실루엣 점수는 클러스터 내의 데이터 포인트들이 얼마나 잘 모여 있는지, 그리고 다른 클러스터와 얼마나 잘 구분되는지를 함께 고려하는 지표이다

⇒ 즉 실루엣 점수는 클러스터의 밀집도와 분리도를 동시에 고려한다 볼 수 있다

- 따라서 일반적으로는 **실루엣 다이어그램을 사용하는 것**이 클러스터링의 성능을 더 정확하게 반영한다고 할 수 있다
</aside>

### 1. 관성과 클러스터

- 클러스터 개수 k가 증가할 수록 관성이작아지므로 좋은 성능 지표가 아니기에 관성이 더 이상 획기적으로 줄어들지 않는 지점의 클러스터 개수 선택하는 방법

### 2. 실루엣 다이어그램과 클러스터

- 실루엣 다이어그램이란 클러스터별 실루엣 계수 모음을 칼 모양의 그래프로 나타낸것
    - 칼 두께 : 클러스터에 포함된 샘플의 개수
    - 칼 길이: 클러스터에 포함된 샘플의 실루엣 계수 길 수록 좋음
    - 대부분의 칼이 빨간 파선보다 길어야함

---

# DBSCAN

- 이것 역시 군집을 이용한 알고리즘으로 군집간의 거리를 사용하는 k-평균과 다르게 밀도 방식의 클러스터링을 사용하는 알고리즘이다

<aside>
❓ **군집을 이용한 알고리즘은 k-평균과 DBSCAN이외에 또 무엇이 있을까?**

k-평균과 DBSCAN 말고도 군집을 이용한 알고리즘. 즉, 클러스터링을 사용하는 알고리즘 중 주요한 알고리즘은 무엇이 있을까?

1. ****K - 중앙값 알고리즘****
- K-평균 알고리즘과 비슷하지만 K-평균 알고리즘이 군집의 중심점을 평균으로 구하는것과 다르게 K-중앙값 알고리즘은 중앙값을 이용한다는 특징을 가진다.
1. ****평균 이동 군집화 알고리즘****
- K-평균 알고리즘이 각 데이터와의 거리를 기반으로 중심점을 업데이트 한다면, 평균 이동 군집화 클러스터링은 **데이터의 밀도가 가장 높은 곳**으로 중심점을 업데이트한다는 특징을 가진다
- 데이터의 밀도를 이용한다는 점에서 DBSCAN와 비슷하나 성능이 좀 더 떨어진다 볼 수 있다. DBSCAM은 평균 이동 군집화 알고리즘과 달리 데이터 점이 아주 어려울때도 군집을 잘 시키기 때문이다
</aside>

- 사이킷런의 DBSCAN 모델은 eps와 min_samples 등 두개의 하이퍼파라미터를 사용한다
- 계산 복잡도의 경우 시간복잡도는 약 𝑂 (𝑚 log 𝑚) 이며 공간 복잡도는 𝑂(m^2)의 메모리를 요구한다

### 장점

- 하이퍼파라미터가 단 두개인 매우 간단하면서 매우 강력한 알고리즘이다
- 군집의 모양과 개수에 상관없으며 이상치에 안정적이다

---

# 가우시안 혼합 모델 (GMM)

- 가우시안 분포는 우리가 일상적으로 ‘정규 분포’라고 부르는 것이며 여러 개의 가우시안 분포를 혼합하여 복잡한 데이터 분포를 모델링하는 방법을 GMM이라고 하고 특히 GMM은 클러스터링에 매우 효과적이다
- GMM 모델규제
    - 특성수가 크거나, 군집수가 많거나, 샘플이 적은 경우 최적 모델 학습 어려움
    - 공분산에 규제를 가해서 학습을 도와줄 수 있음
- GMM 이상치
    - GMM에서 밀도가 임곗값보다 낮은 지역에 있는 샘플을 이상치로 간주 가능하다

### 장점 - 타원형 클러스터에 잘 작동함
단점 - 다른 모양을 가진 데이터 셋에서는 성능이 좋지 않음

## GMM 클러스터 개수 선택

k-평균에서 사용한 관성 또는 실루엣 점수는 군집이 타원형일 때 값이 일정하지 않기 때문에 사용 불가하다

<aside>
❓ **군집이 타원형이면 값이 일정하지 않은 이유?**

- 그 이유는 원형 클러스터와 달리 타원형 클러스터에서는 **데이터 포인트 간의 거리가 일정하지 않다**는 것과 관련이 있다
1. 원형 클러스터에서는 클러스터의 중심에서 모든 방향으로 동일한 거리에 데이터 포인트들이 위치하게 되어 중심에서의 거리를 기준으로 클러스터 내의 데이터 포인트들을 평가하는 것이 가능하다

⇒ 따라서 K-평균 알고리즘에서는 관성 또는 실루엣 점수와 같은 거리 기반의 평가 방법을 사용할 수 있는 것

1. 하지만 반면에 타원형 클러스터에서는 **데이터 포인트 간의 거리가 일정하지 않다!**

⇒ 즉, 클러스터의 중심에서 동일한 거리에 위치한 데이터 포인트들이 같은 클러스터에 속한다는 가정이 성립하지 않음

</aside>

- 이론적 정보 기준인 BIC와 AIC를 최소화 하는 모델 선택 가능함

## 베이즈 가우시안 혼합 모델

- 최적의 클러스터 개수를 수동으로 찾지 않고 불필요한 클러스터의 가중치를 0으로 만드는 BayesianGaussianMixture 모델
