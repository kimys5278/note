# 9주차 과제 1

상태: 시작 전

1. 기계 학습에서 학습이란 무엇인지를 정리하시오(2점).

( 가중치, 손실함수가 무엇인지를 정리하고, 데이터, 가중치, 손실함수를 이용하여 학습이 무엇인지를 정리함.)

---

기계 학습에서의 '학습'은 주어진 데이터를 바탕으로 가중치를 조정하며 손실함수의 값을 줄여나가는 과정인데 여기서 ‘가중치’ 와 ‘손실함수’가 뭔지를 정의하자면 먼저 가중치란 기계 학습 모델에서  각 입력 특성에 부여되어 그 중요도를 조절하는 역할을 하는데 가중치가 클수록 해당 특성이 출력에 큰 영향을 미치게된다. 그 다음으로 손실함수란 모델의 예측값과 실제 값 사이의 차이를 수치화하는 것으로 손실함수가 적을수록 모델의 성능이 좋다고 판단한다. 한마디로 손실함수의 값이 점점 줄어들면서 가중치가 최적화시키는 것을 학습이라 한다.

2 . 소스코드분석

![기계학습.png](9%E1%84%8C%E1%85%AE%E1%84%8E%E1%85%A1%20%E1%84%80%E1%85%AA%E1%84%8C%E1%85%A6%201%20b52297f1634c4b1987229428868978cf/%25EA%25B8%25B0%25EA%25B3%2584%25ED%2595%2599%25EC%258A%25B5.png)

1. **`n_epochs = 50`**
    - **`n_epochs`** 변수를 50으로 설정합니다. 이는 알고리즘이 전체 데이터 세트를 통해 학습을 반복할 횟수, 즉 에포크 수를 나타냄.
2. **`t0, t1 = 5, 50`**
    - 학습 스케줄링에 사용될 두 개의 파라미터 **`t0`**와 **`t1`**을 설정합니다. 이들은 학습률을 조정하는 데 사용.
3. **`def learning_schedule(t):`**
    - 학습률을 조정하기 위한 함수 **`learning_schedule`**을 정의합니다. 이 함수는 시간 t에 따라 학습률을 조정하는 역할.
4. **`return t0 / (t + t1)`**
    - **`learning_schedule`** 함수는 호출될 때마다 학습률을 **`t0`** 나누기 **`(t + t1)`**로 계산해 반환합니다. 시간 **`t`**가 증가함에 따라 학습률은 감소할 거라 생각됨.
5. **`theta = np.random.rand(2,1)`**
    - 무작위 값으로 이루어진 2x1 형태의 배열을 생성하여 **`theta`** 변수에 할당합니다. 이는 최적화될 파라미터들의 초기값을 의미.
        - **`n_epochs`**만큼 에포크를 반복.
6. **`for i in range(m):`**
    - 각 에포크마다 **`m`**번 반복하는 내부 for 루프를 시작합니다. 여기서 **`m`**은 코드 상에 정의되지 않았지만, 일반적으로 데이터 포인트의 총 수를 나타내는 변수.
7. **`random_index = np.random.randint(m)`**
    - **`0`**에서 **`m-1`** 사이의 무작위 정수를 하나 생성합니다. 이는 무작위로 선택된 데이터 포인트의 인덱스.
8. **`xi = X[random_index:random_index+1]`**
    - **`X`** 배열(데이터 포인트를 포함)에서 무작위로 선택된 데이터 포인트를 추출.
9. **`yi = y[random_index:random_index+1]`**
    - **`y`** 배열(타겟 값을 포함)에서 위에서 선택된 데이터 포인트에 해당하는 타겟 값을 추출..
10. **`gradients = 2 * xi.T.dot(xi.dot(theta) - yi)`**
    - 경사(gradient)를 계산합니다. 이는 비용 함수의 기울기를 나타내며, 데이터 포인트에 대한 파라미터 **`theta`**의 오차를 줄이기 위해 사용.
11. **`eta = learning_schedule(epoch * m + i)`**
    - 현재 에포크와 반복을 고려하여 **`learning_schedule`** 함수를 사용하여 학습률 **`eta`**를 계산.
12. **`theta = theta - eta * gradients`**
    - 계산된 경사와 학습률을 사용하여 **`theta`**를 업데이트합니다. 이는 모델의 파라미터를 조정하여 비용 함수의 값을 최소화하는 과정.