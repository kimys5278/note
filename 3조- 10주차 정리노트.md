# 10주차 정리노트

상태: 시작 전

# **201904197 김유성**

---

## 차원축소(Dimensionality Reduction)

차원축소는 고차원 데이터를 저차원으로 변환하는 기법입니다. 이를 통해 데이터의 복잡성을 감소시키고, 데이터 시각화, 효율적인 학습 및 모델링 등에 활용할 수 있습니다.

### 주요 개념

- **고차원 데이터**: 많은 특성 또는 변수로 이루어진 데이터를 의미합니다. 예를 들어, 이미지 데이터의 경우 각 픽셀이 특성이 되어 고차원 데이터를 형성합니다.
- **저차원 데이터**: 고차원 데이터를 표현하는데 필요한 차원 수를 줄인 데이터를 의미합니다. 이는 원래 데이터의 정보를 최대한 보존하면서 차원을 축소하는 것이 목표입니다.
- **주성분 분석(PCA)**: 가장 대표적인 차원축소 알고리즘으로, 고차원 데이터의 분산을 최대한 보존하는 방식으로 저차원으로 변환합니다.
- **특이값 분해(SVD)**: PCA와 밀접한 관련이 있는 선형대수의 개념으로, 행렬을 세 개의 행렬로 분해하는 과정입니다.

### 차원축소의 장점

- **시각화**: 고차원 데이터를 저차원으로 변환하여 시각화할 수 있습니다. 이를 통해 데이터의 패턴이나 관계를 직관적으로 파악할 수 있습니다.
- **계산 효율성**: 저차원 데이터로 모델을 학습하거나 예측하는 데에 필요한 계산량이 감소합니다.
- **노이즈 제거**: 차원축소는 불필요한 특성이나 잡음을 제거하는 효과를 가지며, 데이터의 중요한 특성에 집중할 수 있게 합니다.

차원축소는 데이터 분석과 머신러닝에서 중요한 기법 중 하나입니다. 다양한 알고리즘과 방법론이 존재하며, 데이터의 특성과 목적에 맞게 선택하여 활용해야 합니다.

실무에서 차원 축소는 다양한 분야에서 활용됩니다. 예를 들어, 고차원의 이미지 데이터를 저차원으로 축소하여 시각화할 수 있습니다. 이를 통해 이미지의 패턴이나 특징을 파악할 수 있고, 컴퓨터 비전 분야에서 객체 감지, 얼굴 인식 등에 활용됩니다.

또한, 차원 축소는 텍스트 데이터에서도 유용하게 사용될 수 있습니다. 예를 들어, 자연어 처리에서 단어 임베딩 기법을 사용하여 고차원의 단어 벡터를 저차원으로 축소할 수 있습니다. 이를 통해 단어 간의 의미적 유사성을 측정하거나 문서 간의 유사성을 파악하는데 활용됩니다.

또한, 차원 축소는 머신러닝 모델의 학습과 예측에도 도움이 됩니다. 고차원 데이터에서 불필요한 특성을 제거하고 중요한 특성에 집중함으로써 모델의 복잡성을 줄이고, 계산 효율성을 향상시킬 수 있습니다.

이처럼 실무에서는 차원 축소를 데이터 분석, 머신러닝, 컴퓨터 비전, 자연어 처리 등 다양한 분야에서 활용하여 데이터의 복잡성을 감소시키고 유용한 정보를 추출하는 데에 활용됩니다.

# 차원 축소: LLE (Locally Linear Embedding)

LLE (Locally Linear Embedding)은 차원 축소의 한 종류로, 데이터의 국소적인 선형 관계를 보존하는 방식으로 데이터를 저차원으로 변환합니다.

LLE는 다음과 같은 단계로 이루어집니다:

1. **이웃 선정**: 각 데이터 포인트에 대해 근접한 이웃을 선정합니다. 이는 데이터 포인트 주변의 가까운 이웃들을 선택하는 것을 의미합니다.
2. **국소적인 선형 관계 재현**: 이웃들 간의 선형 관계를 재현하기 위해 가중치를 찾습니다. 이 가중치는 이웃들 사이의 선형 조합으로 표현됩니다.
3. **저차원 재현**: 이웃들 간의 선형 관계를 최대한 보존하는 저차원 표현을 찾습니다. 이를 통해 데이터를 저차원으로 변환합니다.

LLE은 주로 비선형 데이터의 저차원 표현을 찾는 데에 사용됩니다. 이 알고리즘은 데이터의 국소적인 구조를 잘 파악하고, 비선형 특성을 보존하면서 데이터를 저차원으로 표현할 수 있습니다. 따라서 LLE은 데이터 시각화와 비선형 패턴 인식에 유용하게 활용될 수 있습니다.

LLE은 차원 축소의 대표적인 알고리즘 중 하나이며, 다양한 응용 분야에서 활용되고 있습니다. 예를 들어, 얼굴 인식, 음성 인식, 자연어 처리 등 다양한 분야에서 비선형 데이터를 저차원으로 변환하는 데에 활용됩니다.

# 커널 PCA (Kernel PCA)

커널 PCA는 주성분 분석(PCA)을 비선형 데이터에 적용하기 위한 기법입니다. PCA는 데이터의 분산을 최대화하여 주성분을 찾아내는 선형 차원 축소 방법입니다. 하지만 PCA는 선형 변환만을 고려하기 때문에, 비선형 데이터의 경우에는 제대로 동작하지 않을 수 있습니다.

커널 PCA는 이러한 문제를 해결하기 위해 커널 트릭을 사용합니다. 커널 트릭은 비선형 공간에서의 내적 연산을 선형 공간에서의 내적으로 변환하는 방법입니다. 커널 PCA는 데이터를 높은 차원으로 매핑한 후, 선형 PCA를 적용하여 저차원으로 투영합니다.

커널 PCA의 주요 단계는 다음과 같습니다:

1. **커널 행렬 계산**: 주어진 데이터 샘플들 간의 유사도를 계산하여 커널 행렬을 구성합니다. 대표적인 커널 함수로는 가우시안 커널, 다항식 커널, 시그모이드 커널 등이 있습니다.
2. **고유값 분해**: 커널 행렬에 대한 고유값 분해를 수행하여 고유값과 고유벡터를 구합니다.
3. **주성분 선택**: 고유값이 큰 순서대로 주성분을 선택합니다.
4. **주성분 투영**: 주성분을 이용하여 데이터를 저차원으로 투영합니다.

커널 PCA는 비선형 데이터의 특징을 잘 파악하면서도 저차원으로 표현할 수 있는 장점을 가지고 있습니다. 따라서 비선형 데이터의 차원 축소나 분류, 패턴 인식 등에 유용하게 활용될 수 있습니다.

커널 PCA는 머신러닝, 컴퓨터 비전, 자연어 처리 등 다양한 분야에서 활용되고 있습니다. 예를 들어, 얼굴 인식에서 비선형 데이터를 저차원으로 변환하여 특징을 추출하거나, 자연어 처리에서 텍스트 데이터의 비선형 특징을 저차원으로 표현하는 데에 사용됩니다.

# 차원 축소: Isomap

Isomap은 차원 축소의 한 종류로서 데이터의 지리적 구조를 유지하면서 데이터를 저차원으로 변환하는 방법입니다.

Isomap은 다음과 같은 단계로 이루어집니다:

1. **이웃 그래프 생성**: 각 데이터 포인트 간의 거리를 측정하여 이웃 그래프를 생성합니다. 이웃 그래프는 가까이에 위치한 데이터 포인트들을 연결하여 그래프를 형성합니다.
2. **지리적 거리 추정**: 이웃 그래프를 기반으로 각 데이터 포인트 간의 지리적 거리를 추정합니다. 이를 위해 최단 경로 알고리즘을 사용합니다.
3. **저차원 재현**: 추정된 지리적 거리를 유지하면서 저차원으로 데이터를 변환합니다. 이를 위해 다차원 척도법(MDS)을 사용합니다.

Isomap은 데이터의 지리적 구조를 고려하므로 비선형 데이터의 특징을 잘 파악할 수 있습니다. 이 알고리즘은 지리적 유사성이 중요한 문제에 유용하게 적용될 수 있습니다. 예를 들어, 지리 데이터에서 지리적인 거리를 보존하면서 데이터를 저차원으로 변환하여 지도상의 클러스터를 시각화할 수 있습니다.

Isomap은 차원 축소의 대표적인 알고리즘 중 하나이며, 다양한 응용 분야에서 활용되고 있습니다. 예를 들어, 로봇 공학에서 로봇의 자세 제어에 활용되거나, 생물 정보학에서 단백질 구조 예측에 사용될 수 있습니다.

# 이동현

---

차원 축소는 고차원의 데이터를 저차원으로 축소하는 기법입니다. 이를 통해 데이터의 복잡성을 감소시키고 유용한 정보를 추출할 수 있습니다.

주요한 차원 축소 알고리즘으로는 LLE (Locally Linear Embedding), 커널 PCA (Kernel PCA), Isomap 등이 있습니다.

- LLE는 국소적인 선형 관계를 보존하여 데이터를 저차원으로 변환합니다. 비선형 데이터의 표현이 필요한 경우에 유용하게 활용될 수 있습니다.
- 커널 PCA는 주성분 분석 (PCA)을 비선형 데이터에 적용하기 위한 기법입니다. 커널 트릭을 사용하여 비선형 데이터를 고차원으로 매핑한 후, 선형 PCA를 적용하여 저차원으로 투영합니다.
- Isomap은 데이터의 지리적 구조를 유지하면서 데이터를 저차원으로 변환합니다. 지리 데이터에서 지리적인 거리를 보존하면서 데이터를 저차원으로 표현할 수 있습니다.

이러한 차원 축소 알고리즘은 데이터 분석, 머신러닝, 컴퓨터 비전, 자연어 처리 등 다양한 분야에서 활용됩니다. 각 알고리즘은 데이터의 특성과 문제에 따라 선택하여 적용할 수 있습니다.